# pip install selenium beautifulsoup4 requests pillow tqdm
import os
import time

import requests
from PIL import Image
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from tqdm import tqdm

# ğŸ”¹ í¬ë¡¤ë§í•  ê²€ìƒ‰ì–´ ë° ì €ì¥ í´ë” ì§€ì •
SEARCH_QUERY = "í¬ë¡œì™€ìƒ"  # ì›í•˜ëŠ” ê²€ìƒ‰ì–´ë¡œ ë³€ê²½ ê°€ëŠ¥
SAVE_FOLDER = f"images/{SEARCH_QUERY.replace(' ', '_')}"

# ğŸ”¹ ë‹¤ìš´ë¡œë“œí•  ì´ë¯¸ì§€ ê°œìˆ˜
NUM_IMAGES = 200  # ì›í•˜ëŠ” ê°œìˆ˜ ì§€ì •

# ğŸ”¹ Chrome WebDriver ì„¤ì •
CHROME_DRIVER_PATH = "chromedriver.exe"  # í¬ë¡¬ ë“œë¼ì´ë²„ ê²½ë¡œ ì§€ì • (ìš´ì˜ì²´ì œì— ë§ê²Œ ë³€ê²½)
options = Options()
options.add_argument("--headless")  # ë¸Œë¼ìš°ì € ì°½ ì—†ì´ ì‹¤í–‰ (UI í•„ìš”í•˜ë©´ ì œê±°)
options.add_argument("--disable-gpu")
options.add_argument("--window-size=1920x1080")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")

# ğŸ”¹ í´ë” ìƒì„±
os.makedirs(SAVE_FOLDER, exist_ok=True)

# ğŸ”¹ ì›¹ ë“œë¼ì´ë²„ ì‹¤í–‰
service = Service(CHROME_DRIVER_PATH)
driver = webdriver.Chrome(service=service, options=options)
search_url = f"https://www.google.com/search?q={SEARCH_QUERY}&tbm=isch"
driver.get(search_url)


# ğŸ”¹ ìŠ¤í¬ë¡¤ì„ ìë™ìœ¼ë¡œ ë‚´ë ¤ ë” ë§ì€ ì´ë¯¸ì§€ ë¡œë“œ
def scroll_to_end(driver):
    last_height = driver.execute_script("return document.body.scrollHeight")

    while True:
        # í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)  # ë¡œë”© ì‹œê°„ ëŒ€ê¸°

        # ë” ë§ì€ ì´ë¯¸ì§€ ë²„íŠ¼ í´ë¦­ (ìˆì„ ê²½ìš°)
        try:
            more_button = driver.find_element(By.XPATH, '//input[@type="button" and @value="Show more results"]')
            more_button.click()
            time.sleep(2)
        except:
            pass

        # ìŠ¤í¬ë¡¤ í›„ ë†’ì´ í™•ì¸
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            break  # ë” ì´ìƒ ìŠ¤í¬ë¡¤í•  ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
        last_height = new_height


# ğŸ”¹ ìŠ¤í¬ë¡¤ì„ ë‚´ë ¤ ë” ë§ì€ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
scroll_to_end(driver)

# ğŸ”¹ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
time.sleep(2)

# ğŸ”¹ ì´ë¯¸ì§€ URL ìˆ˜ì§‘
soup = BeautifulSoup(driver.page_source, "html.parser")
img_tags = soup.find_all("img")

img_urls = []
for img_tag in img_tags:
    img_url = img_tag.get("src") or img_tag.get("data-src")
    if img_url and "http" in img_url:
        try:
            response = requests.get(img_url, stream=True, timeout=5)
            response.raise_for_status()
            with Image.open(response.raw) as img:
                if img.width > 100 and img.height > 100:  # ì•„ì´ì½˜(100x100 ì´í•˜) ì œì™¸
                    img_urls.append(img_url)
        except Exception:
            pass

# ğŸ”¹ ì¤‘ë³µ ì œê±° ë° ê°œìˆ˜ ì œí•œ
img_urls = list(set(img_urls))[:NUM_IMAGES]


# ğŸ”¹ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
def download_image(url, save_path):
    try:
        response = requests.get(url, stream=True, timeout=5)
        response.raise_for_status()

        # ì›ë³¸ í™•ì¥ì ì¶”ì¶œ í›„ ì„ì‹œ ì €ì¥
        temp_path = save_path + "_temp"

        with open(temp_path, "wb") as file:
            for chunk in response.iter_content(1024):
                file.write(chunk)

        # ì´ë¯¸ì§€ í¬ë§· í™•ì¸ í›„ JPGë¡œ ë³€í™˜
        with Image.open(temp_path) as img:
            img = img.convert("RGB")  # RGB ëª¨ë“œë¡œ ë³€í™˜ (íˆ¬ëª… ë°°ê²½ ì œê±°)
            img.save(save_path, "JPEG")  # JPGë¡œ ì €ì¥

        # ë³€í™˜ í›„ ì›ë³¸ ì‚­ì œ
        os.remove(temp_path)

    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url} | ì˜¤ë¥˜: {e}")
        if os.path.exists(save_path):
            os.remove(save_path)


print(f"ğŸ”½ {SEARCH_QUERY} ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")

for idx, img_url in tqdm(enumerate(img_urls), total=len(img_urls)):
    save_path = os.path.join(SAVE_FOLDER, f"{SEARCH_QUERY}_{idx + 1}.jpg")
    download_image(img_url, save_path)

print(f"âœ… {SEARCH_QUERY} ì´ë¯¸ì§€ {len(img_urls)}ì¥ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
driver.quit()
